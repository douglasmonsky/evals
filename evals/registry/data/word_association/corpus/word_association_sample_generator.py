import json
from logger_config import logger
from typing import List, Optional, Callable, Any
from corpus import NltkCorpus, Corpus
from processor import WordCollectionProcessor
from related_words import DataMuseRelatedWords
from validators import RelatedStrings, SimilarityTuple, EmbeddingsValidator


class EvalTemplate:
    samples = []

    def create_sample(self, system_message: str, user_message: str, ideal_answer: str,) -> dict[str, str | list[str]]:
        sample = {
            "input": [
                {"role": "system", "content": system_message},
                {"role": "user", "content": user_message},
            ],
            "ideal": ideal_answer,
        }
        self.samples.append(sample)
        return sample

    def export_to_jsonl(self, filename: str = "samples.jsonl") -> None:
        with open(filename, "w") as f:
            for sample in self.samples:
                f.write(json.dumps(sample) + "\n")


def generate_word_association_system_message(word: str, related_words: List[str],
                                             parts_of_speech_choices: Optional[List[str]] = None) -> str:
    num_words = len(related_words)
    word_length = len(word)

    message_parts = [
        "We are going to play a game of word association. I want you to guess the secret word.",
        f"I will give you {num_words} words, the secret word is related to all {num_words} of these words.",
        f"The secret word is {word_length} characters long."
    ]

    if parts_of_speech_choices:
        message_parts.append(f"The secret word is one of the following parts of speech: {parts_of_speech_choices}.")

    message_parts.append("What is the secret word? Before answering, reason in a step-by-step manner "
                         "as to get the right answer, then conclude with the answer in the following format: "
                         "The secret word is: [<secret-word.lower()>] because <reasoning>")

    system_message = ' '.join(message_parts)
    return system_message


def taboo_clue_guesser_system_message() -> None:
    """This function is used to generate the system message for the taboo clue guesser eval. This will be similar to
    the word association game, but the task will be to guess the secret word based on a paragraph generated by an LLM
    where use of the related words list is forbidden instead of given."""
    raise NotImplementedError


def taboo_clue_giver_system_message() -> None:
    """This function is used to generate the system message for the taboo clue giver eval. In this case the LLMs task
    will be to generate a paragraph that will help a guesser guess the secret word. The limiting rule will be in line
    with the game taboo's rules, where use of the related words list is forbidden instead of given. This eval will be a
    ModelGradedEval."""
    raise NotImplementedError


def main(corpus: Corpus, related_words_length: int, max_samples: int = -1,
         export_file: Optional[str] = None, *filters: Callable[[Any], Any]) -> None:
    eval_factory = EvalTemplate()

    word_association_pairs: List[RelatedStrings] = []
    # Get related words for each word in the filtered corpus

    for word in corpus:
        related_words = DataMuseRelatedWords(word)

        # Define the processor which will perform the filteration on the related words
        # (currently the only implemented processor works on both corpus and related words)
        related_processor = WordCollectionProcessor(related_words)

        # Filter the related words to remove 'words' that are actually phrases
        related_processor.str_max_word_count_filter(1)
        # Filter the related words to remove words that are too long
        related_processor.sub_word_filter(word)

        # Apply additional filter functions
        for filter_func in filters:
            related_words = filter_func(related_words)

        related_words = related_processor.words.words
        if len(related_words) >= related_words_length:
            related_words = related_words[:related_words_length]
            logger.info(f"Word: {word}, Related Words: {related_words}")
            word_association_pairs.append(RelatedStrings(word, "|".join(related_words)))
            # generate the system message for each word association
        else:
            logger.info(f"Word: {word}, Related Words: {related_words}, Skipped - Not Enough Related Words")

    validator = EmbeddingsValidator(0.75)
    similarities: List[SimilarityTuple] = validator.validate(word_association_pairs)

    valid_samples: List[RelatedStrings] = [word_association_pair for word_association_pair, similarity
                                           in similarities if similarity]
    logger.info(f"Total Sample: {len(word_association_pairs)} Valid Samples: {len(valid_samples)}")
    for word, related_words in valid_samples:
        system_message = generate_word_association_system_message(word, related_words.split("|"),
                                                                  parts_of_speech_choices=["noun", "verb"])
        eval_factory.create_sample(system_message, f"Here is a list of"
                                                   f" the related words: {related_words}", f"[{word}]")
        # If the maximum number of samples have been created, break the loop
        if max_samples != -1 and len(eval_factory.samples) >= max_samples:
            break

    if export_file is None:
        export_file = f"related_words_{related_words_length}.jsonl"
    eval_factory.export_to_jsonl(filename=export_file)


if __name__ == "__main__":
    # define the baseline corpus
    corpus = NltkCorpus("words")
    # define the processor which will perform the filteration of the baseline corpus
    processor = WordCollectionProcessor(corpus)

    # Filter the baseline corpus against frequency distribution of another corpus
    freq_filter_corpus = NltkCorpus("brown")
    processor.frequency_filter(thresholds=(50, 10000), filter_corpus=freq_filter_corpus)

    # Filter the baseline corpus against length and parts of speech
    processor.char_length_filter(length_bounds=(5, 5))
    processor.parts_of_speech_filter(["NN", "VB"])
    filtered_corpus = processor.words

    # Generate the evals
    main(filtered_corpus, related_words_length=5)
